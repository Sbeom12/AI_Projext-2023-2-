{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NnosZTMT_OT3",
        "outputId": "7aede119-e31d-4756-9d61-c8b59f2563f2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "naver = pd.read_csv('/content/drive/MyDrive/딥러닝 공부/연구실 프로젝트 1/naver_token')\n",
        "steam = pd.read_csv('/content/drive/MyDrive/딥러닝 공부/연구실 프로젝트 1/steam_token')\n",
        "total = pd.read_csv('/content/drive/MyDrive/딥러닝 공부/연구실 프로젝트 1/total_token')"
      ],
      "metadata": {
        "id": "kFgsN0zu_PM5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "naver.head(2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "qZ2BGU8H_fau",
        "outputId": "e3261963-ba0f-40df-9bf7-d842ff9a19ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             데이터  label  \\\n",
              "0                        배공빠르고 굿      1   \n",
              "1  택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고      0   \n",
              "\n",
              "                                           tokenized  \n",
              "0                                  ['배공', '빠르', '굿']  \n",
              "1  ['택배', '엉망', '용', '저희', '집', '밑', '층', '말', '없...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43a46240-6846-447f-84a2-cf5d109c8139\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>데이터</th>\n",
              "      <th>label</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>배공빠르고 굿</td>\n",
              "      <td>1</td>\n",
              "      <td>['배공', '빠르', '굿']</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>택배가 엉망이네용 저희집 밑에층에 말도없이 놔두고가고</td>\n",
              "      <td>0</td>\n",
              "      <td>['택배', '엉망', '용', '저희', '집', '밑', '층', '말', '없...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43a46240-6846-447f-84a2-cf5d109c8139')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43a46240-6846-447f-84a2-cf5d109c8139 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43a46240-6846-447f-84a2-cf5d109c8139');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter\n",
        "\n",
        "naver_n = np.hstack(naver[naver.label == 0]['tokenized'].values)\n",
        "naver_p = np.hstack(naver[naver.label == 1]['tokenized'].values)\n",
        "steam_n = np.hstack(steam[steam.label == 0]['tokenized'].values)\n",
        "steam_p = np.hstack(steam[steam.label == 1]['tokenized'].values)\n",
        "total_n = np.hstack(total[total.label == 0]['tokenized'].values)\n",
        "total_p = np.hstack(total[total.label == 1]['tokenized'].values)\n",
        "\n",
        "naver_n_count = Counter(naver_n)\n",
        "naver_p_count = Counter(naver_p)\n",
        "steam_n_count = Counter(steam_n)\n",
        "steam_p_count = Counter(steam_p)\n",
        "total_n_count = Counter(total_n)\n",
        "total_p_count = Counter(total_p)\n",
        "print('네이버 토큰 단어 확인')\n",
        "# 최빈 값 20개 확인해보기\n",
        "print(naver_n_count.most_common(20))\n",
        "print(naver_p_count.most_common(20))\n",
        "\n",
        "print('스팀 토큰 단어 확인')\n",
        "# 최빈 값 20개 확인해보기\n",
        "print(steam_n_count.most_common(20))\n",
        "print(steam_p_count.most_common(20))\n",
        "\n",
        "print('전체 토큰 단어 확인')\n",
        "# 최빈 값 20개 확인해보기\n",
        "print(total_n_count.most_common(20))\n",
        "print(total_p_count.most_common(20))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XXDfjfj_k6L",
        "outputId": "e2314f30-6833-45f2-d807-c8f564f5e58a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "네이버 토큰 단어 확인\n",
            "[(\"['재', '구매']\", 26), (\"['배송', '너무', '느려요']\", 17), (\"['그냥', '그래요']\", 9), (\"['좋', '아요']\", 9), (\"['배송', '빠르', '좋', '아요']\", 9), (\"['배송', '빨', '라요']\", 7), (\"['생각', '보다', '별로', '네요']\", 7), (\"['잘', '받', '았', '습니다']\", 7), (\"['그저', '그래요']\", 7), (\"['별로', '에요']\", 7), (\"['배송', '너무', '느', '립니']\", 7), (\"['별로']\", 6), (\"['사이즈', '작', '아요']\", 6), (\"['별루', '입니다']\", 6), (\"['배송', '느림']\", 5), (\"['냄새', '심해요']\", 5), (\"['배송', '너무', '늦', '네요']\", 5), (\"['배송', '너무', '늦', '어요']\", 5), (\"['별로', '예', '요']\", 5), (\"['배송', '겁나', '느림']\", 5)]\n",
            "[(\"['재', '구매']\", 29), (\"['좋', '아요']\", 14), (\"['좋', '습니다']\", 9), (\"['만족', '합니다']\", 8), (\"['감사', '합니다']\", 8), (\"['배송', '빨', '라요']\", 7), (\"['굿']\", 6), (\"['조아', '요']\", 6), (\"['잘', '받', '았', '습니다']\", 6), (\"['좋', '네요']\", 5), (\"['빠른', '배송', '감사', '합니다']\", 5), (\"['배송', '빠르', '네요']\", 5), (\"['배송', '빠르', '좋', '네요']\", 5), (\"['맘', '어요']\", 4), (\"['괜찮', '아요']\", 4), (\"['재', '구매', '빠른', '배송', '감사', '합니다']\", 4), (\"['맛있', '어요']\", 4), (\"['배송', '빠르', '좋', '아요']\", 4), (\"['재', '구매', '배송', '빠르', '좋', '아요']\", 4), (\"['착용감', '좋', '아요']\", 4)]\n",
            "스팀 토큰 단어 확인\n",
            "[(\"['노', '잼']\", 18), (\"['망', '겜']\", 17), ('[]', 13), (\"['별로']\", 11), (\"['사람', '없']\", 9), (\"['시발']\", 8), (\"['겜']\", 7), (\"['재미', '없', '음']\", 7), (\"['사람', '없', '음']\", 6), (\"['재미', '없']\", 6), (\"['이게', '게임', '냐']\", 6), (\"['병신', '겜']\", 5), (\"['개', '노', '잼']\", 5), (\"['돈', '아깝']\", 5), (\"['최악']\", 5), (\"['아']\", 5), (\"['마']\", 5), (\"['쓰레기']\", 5), (\"['사', '마']\", 5), (\"['실행', '안', '됨']\", 5)]\n",
            "[(\"['갓', '겜']\", 19), (\"['꿀', '잼']\", 17), ('[]', 8), (\"['개꿀', '잼']\", 8), (\"['최고', '게임']\", 6), (\"['한글', '패치']\", 6), (\"['재밌', '어요']\", 6), (\"['도전', '과제', '개']\", 6), (\"['명작']\", 6), (\"['시발']\", 5), (\"['너무', '재밌', '어요']\", 5), (\"['말', '필요', '없']\", 5), (\"['플레이', '타임', '분', '전', '과제', '개', '효율', '분', '약', '개', '도전', '과제', '딸', '수', '있', '음']\", 5), (\"['최고']\", 5), (\"['정말', '재밌', '어요']\", 4), (\"['귀엽']\", 4), (\"['말', '필요', '없', '갓', '겜']\", 4), (\"['시간', '순삭']\", 4), (\"['뇌', '아픈']\", 4), (\"['재미있']\", 4)]\n",
            "전체 토큰 단어 확인\n",
            "[(\"['재', '구매']\", 26), (\"['노', '잼']\", 18), (\"['별로']\", 17), (\"['배송', '너무', '느려요']\", 17), (\"['망', '겜']\", 17), ('[]', 14), (\"['그냥', '그래요']\", 10), (\"['좋', '아요']\", 10), (\"['배송', '빠르', '좋', '아요']\", 9), (\"['사람', '없']\", 9), (\"['생각', '보다', '별로', '네요']\", 8), (\"['별로', '에요']\", 8), (\"['시발']\", 8), (\"['배송', '빨', '라요']\", 7), (\"['잘', '받', '았', '습니다']\", 7), (\"['그저', '그래요']\", 7), (\"['배송', '너무', '느', '립니']\", 7), (\"['겜']\", 7), (\"['재미', '없', '음']\", 7), (\"['사이즈', '작', '아요']\", 6)]\n",
            "[(\"['재', '구매']\", 29), (\"['갓', '겜']\", 19), (\"['꿀', '잼']\", 17), (\"['좋', '아요']\", 16), (\"['좋', '습니다']\", 11), (\"['만족', '합니다']\", 9), (\"['굿']\", 8), (\"['감사', '합니다']\", 8), ('[]', 8), (\"['개꿀', '잼']\", 8), (\"['좋', '네요']\", 7), (\"['배송', '빨', '라요']\", 7), (\"['조아', '요']\", 6), (\"['잘', '받', '았', '습니다']\", 6), (\"['너무', '좋', '아요']\", 6), (\"['최고', '게임']\", 6), (\"['한글', '패치']\", 6), (\"['재밌', '어요']\", 6), (\"['도전', '과제', '개']\", 6), (\"['명작']\", 6)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 길이 비교\n",
        "naver_p_len = naver[naver['label']==1]['tokenized'].map(lambda x: len(x))\n",
        "steam_p_len  = steam[steam['label']==1]['tokenized'].map(lambda x: len(x))\n",
        "total_p_len  = total[total['label']==1]['tokenized'].map(lambda x: len(x))\n",
        "print('긍정 리뷰의 평균 길이 정도')\n",
        "print('네이버 : ', np.mean(naver_p_len))\n",
        "print('스팀 : ', np.mean(steam_p_len))\n",
        "print('전체 : ', np.mean(total_p_len))\n",
        "\n",
        "naver_n_len = naver[naver['label']==0]['tokenized'].map(lambda x: len(x))\n",
        "steam_n_len  = steam[steam['label']==0]['tokenized'].map(lambda x: len(x))\n",
        "total_n_len  = total[total['label']==0]['tokenized'].map(lambda x: len(x))\n",
        "print('부정 리뷰의 평균 길이 정도')\n",
        "print('네이버 : ', np.mean(naver_n_len))\n",
        "print('스팀 : ', np.mean(steam_n_len))\n",
        "print('전체 : ', np.mean(total_n_len))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGk8eBKpFHUv",
        "outputId": "377dd233-9ad4-4928-90a0-af38c4b646f0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "긍정 리뷰의 평균 길이 정도\n",
            "네이버 :  77.66683006862883\n",
            "스팀 :  92.04580366429315\n",
            "전체 :  82.46137122965196\n",
            "부정 리뷰의 평균 길이 정도\n",
            "네이버 :  97.6548319327731\n",
            "스팀 :  93.83281003139811\n",
            "전체 :  96.38410600442796\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 정수 인코딩\n",
        "* 컴퓨터가 학습을 잘하기 위해서 텍스트보다는 숫자를 훨씬 더 잘 처리하기 때문에\n",
        "위에 토큰 단어마다의 고유의 정수를 매핑하는 정수 인코딩을 사용\n"
      ],
      "metadata": {
        "id": "WqULEK55KX40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 학습 및 test 데이터 분리\n",
        "naver_train, naver_test = train_test_split(naver, test_size = 0.25, random_state = 42)\n",
        "steam_train, steam_test = train_test_split(steam, test_size = 0.25, random_state = 42)\n",
        "total_train, total_test = train_test_split(total, test_size = 0.25, random_state = 42)\n",
        "\n",
        "# 토큰화 단어만 분리\n",
        "n_train = naver_train['tokenized'].values\n",
        "s_train = steam_train['tokenized'].values\n",
        "t_train = total_train['tokenized'].values\n",
        "n_test = naver_test['tokenized'].values\n",
        "s_test = steam_test['tokenized'].values\n",
        "t_test = total_test['tokenized'].values\n",
        "\n",
        "# 정답 분리\n",
        "n_y_train = naver_train['label'].values\n",
        "s_y_train = steam_train['label'].values\n",
        "t_y_train = total_train['label'].values\n",
        "\n",
        "n_y_test = naver_test['label'].values\n",
        "s_y_test = steam_test['label'].values\n",
        "t_y_test = total_test['label'].values"
      ],
      "metadata": {
        "id": "oiJGVeMxGRZE"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토큰나이저 사용\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(n_train)"
      ],
      "metadata": {
        "id": "q8MWsRELMasf"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 2 # 1번 이하인 빈도수 팍악을 위해서 사용\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 빈도수\n",
        "\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZjHPI7tLNum",
        "outputId": "6eecfea9-805b-4db7-ffc8-1db10364e485"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 40168\n",
            "등장 빈도가 1번 이하인 희귀 단어의 수: 18302\n",
            "단어 집합에서 희귀 단어의 비율: 45.56363274248158\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 0.7972230050803256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 전체 희귀 단어의 비율은 높지만, 전체 등장 빈도에서 희귀 단어의 등장 빈도 비율이 1%도 안되므로 이를 학습과정에서 제외"
      ],
      "metadata": {
        "id": "6TJCQMznM656"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "print('단어 집합의 크기 :',vocab_size) # 단어의 집합의 크기가 많이 감소됨."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IGGbmOPELeQ_",
        "outputId": "88eb74dd-a6cb-4e58-de87-1750dcb53c91"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 21868\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* oov 토큰 사용.\n",
        "  * oov = out of vocabulary의 의미로 train에서 빈도수가 낮은 단어들을 무시하지는 않지만, 특정 값으로 토큰화 한다."
      ],
      "metadata": {
        "id": "7mer4rpbNXzC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(n_train)\n",
        "# 숫자로 변환\n",
        "naver_X_train = tokenizer.texts_to_sequences(n_train)\n",
        "naver_X_test = tokenizer.texts_to_sequences(n_test)"
      ],
      "metadata": {
        "id": "T-Y06jAgLgn0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정수 인코딩 결과의 확인\n",
        "print(naver_X_train[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGbMGTtBN3Yd",
        "outputId": "77b17a49-60db-4825-e12c-03edb7ff4790"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[21, 9, 729, 244, 1682, 30, 3, 6, 116, 437, 492], [21, 9, 11, 106, 72, 482, 45, 222, 326, 131, 30, 21, 9, 14, 4, 544, 29, 40, 179, 5873, 14334, 7, 58, 33, 12, 100, 701, 59, 740]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 패딩\n",
        "* 리뷰들의 길이가 서로 다르므로 이를 반영할 수 있도록 리뷰의 최대 길이를 확인한다."
      ],
      "metadata": {
        "id": "4wnbcAs3OXDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 길이 및 평균 길이 파악\n",
        "print('리뷰의 최대 길이 :',max(len(review) for review in n_train))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, n_train))/len(n_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQVNO2V3N9Yp",
        "outputId": "19085fc4-cf9b-44c9-8d67-8c84147c0e52"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰의 최대 길이 : 426\n",
            "리뷰의 평균 길이 : 87.66183355787058\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 길이 만큼의 길이를 늘려줌.\n",
        "max_len = 426\n",
        "naver_X_train = pad_sequences(naver_X_train, maxlen=max_len)\n",
        "naver_X_test = pad_sequences(naver_X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "fxUev1EROkEA"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결과 확인\n",
        "naver_X_test[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DprS9xnJO8V9",
        "outputId": "8999da7b-5e35-48e7-d0c9-7d6827f7cdd3"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,   41, 1183,  127, 2646,\n",
              "         647, 5525,  115, 2897,  163, 2643,   26,   74]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 스팀 및 전체 데이터에 대해서도 진행."
      ],
      "metadata": {
        "id": "eRwS0h9PPFvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 스팀\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(s_train)\n",
        "\n",
        "threshold = 2 # 1번 이하인 빈도수 팍악을 위해서 사용\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 빈도수\n",
        "\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI9awZUcO-ly",
        "outputId": "9492344b-fe6d-40c3-8ff6-c57873aa73b2"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 32993\n",
            "등장 빈도가 1번 이하인 희귀 단어의 수: 13998\n",
            "단어 집합에서 희귀 단어의 비율: 42.42718152335344\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 1.152022912071633\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1% 대이므로 제거\n",
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "print('단어 집합의 크기 :',vocab_size) # 단어의 집합의 크기가 많이 감소됨."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJW0stT6PNlN",
        "outputId": "43ad1720-62b7-4f10-d5c4-fe6804ff2bf0"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 18997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(s_train)\n",
        "# 숫자로 변환\n",
        "steam_X_train = tokenizer.texts_to_sequences(s_train)\n",
        "steam_X_test = tokenizer.texts_to_sequences(s_test)"
      ],
      "metadata": {
        "id": "7-U5KGMHPURV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 길이 및 평균 길이 파악\n",
        "print('리뷰의 최대 길이 :',max(len(review) for review in s_train))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, n_train))/len(s_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "itQwnxWyPZxA",
        "outputId": "93b57fff-41a9-4bee-b14c-5f8536a3aa40"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰의 최대 길이 : 411\n",
            "리뷰의 평균 길이 : 175.25353671382285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 길이 만큼의 길이를 늘려줌.\n",
        "max_len = 411\n",
        "steam_X_train = pad_sequences(steam_X_train, maxlen=max_len)\n",
        "steam_X_test = pad_sequences(steam_X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "1somkNOfPcnk"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 확인\n",
        "steam_X_train[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cNsZE9wPhr8",
        "outputId": "fa03afa4-dce9-40ae-df5a-b7821ae9c041"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,   76,   24,   72,   92,   12,   26,    3,   74,\n",
              "        2661, 5162,   28,    3,   36,    8,   88,    7,    4,  418,   12,\n",
              "         152,  819,  591,   68]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전체\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(t_train)\n",
        "\n",
        "threshold = 2 # 1번 이하인 빈도수 팍악을 위해서 사용\n",
        "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
        "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수\n",
        "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
        "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 빈도수\n",
        "\n",
        "for key, value in tokenizer.word_counts.items():\n",
        "    total_freq = total_freq + value\n",
        "\n",
        "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
        "    if(value < threshold):\n",
        "        rare_cnt = rare_cnt + 1\n",
        "        rare_freq = rare_freq + value\n",
        "\n",
        "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
        "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
        "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
        "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoqgJK10Pq6F",
        "outputId": "513a174b-4955-4785-8774-375d902962bf"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합(vocabulary)의 크기 : 56234\n",
            "등장 빈도가 1번 이하인 희귀 단어의 수: 24380\n",
            "단어 집합에서 희귀 단어의 비율: 43.354554184301314\n",
            "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 0.6953037904323575\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1% 미만 대이므로 제거\n",
        "vocab_size = total_cnt - rare_cnt + 2\n",
        "print('단어 집합의 크기 :',vocab_size) # 단어의 집합의 크기가 많이 감소됨."
      ],
      "metadata": {
        "id": "4iMabVF6PxS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(vocab_size, oov_token = 'OOV')\n",
        "tokenizer.fit_on_texts(t_train)\n",
        "# 숫자로 변환\n",
        "total_X_train = tokenizer.texts_to_sequences(t_train)\n",
        "total_X_test = tokenizer.texts_to_sequences(t_test)"
      ],
      "metadata": {
        "id": "Bq6y56BiP0V6"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 길이 및 평균 길이 파악\n",
        "print('리뷰의 최대 길이 :',max(len(review) for review in t_train))\n",
        "print('리뷰의 평균 길이 :',sum(map(len, n_train))/len(t_train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOxc3gs0P5fn",
        "outputId": "02152009-9493-4c26-f7d7-01ac9a7d028c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "리뷰의 최대 길이 : 426\n",
            "리뷰의 평균 길이 : 58.43498672926364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 최대 길이 만큼의 길이를 늘려줌.\n",
        "max_len = 426\n",
        "total_X_train = pad_sequences(total_X_train, maxlen=max_len)\n",
        "total_X_test = pad_sequences(total_X_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "GNpY3iueP9g_"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 확인\n",
        "total_X_train[:1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsCWQa2wP_Xp",
        "outputId": "bf2fdf61-c22d-43fa-b5ac-2a5fe57398c2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,   64,  106,  214, 4017,   19, 3818]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    }
  ]
}